name: Run Scraper üöÄ

on:
  workflow_dispatch: # –†—ä—á–Ω–æ –ø—É—Å–∫–∞–Ω–µ –∑–∞ –∏—Å—Ç–∏–Ω—Å–∫–∏ hustlers
  # schedule:        # –ê–∫–æ –∏—Å–∫–∞—à –¥–∞ —Å–µ –ø—É—Å–∫–∞ —Å–∞–º
  #   - cron: '0 */6 * * *' 

jobs:
  scrape-job:
    runs-on: ubuntu-latest
    
    # ‚ö†Ô∏è –í–ê–ñ–ù–û: –î–∞–≤–∞–º–µ –ø—Ä–∞–≤–∞ –Ω–∞ —Å–∫—Ä–∏–ø—Ç–∞ –¥–∞ –ø–∏—à–µ –≤ —Ä–µ–ø–æ—Ç–æ!
    permissions:
      contents: write
    
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install webdriver-manager pandas selenium openpyxl

      # –¢–£–ö –ï –ú–ê–ì–ò–Ø–¢–ê: –°–∫—Ä–∏–ø—Ç—ä—Ç –≤—ä—Ä—Ç–∏, –≤—ä—Ä—Ç–∏ –∏ —Ç—Ä—É–ø–∞ –¥–∞–Ω–Ω–∏ –≤ –ø–∞–ø–∫–∞—Ç–∞
      - name: Run Scraper Script (Grind Mode)
        id: scraper
        run: python main.py
        continue-on-error: true # –î–æ—Ä–∏ –¥–∞ –≥—Ä—ä–º–Ω–µ Python-–∞, –ø—Ä–æ–¥—ä–ª–∂–∞–≤–∞–º–µ –∫—ä–º –∑–∞–ø–∏—Å–∞!

      # üíæ –ö–ê–ß–í–ê–ú–ï –î–ê–ù–ù–ò–¢–ï –ö–ê–¢–û ARTIFACT (–ó–∞ –≤—Å–µ–∫–∏ —Å–ª—É—á–∞–π)
      - name: Upload Data Artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: Hapche-Data-Part-${{ github.run_id }}
          path: scraped_data/

      # üß† –ó–ê–ü–ê–ó–í–ê–ú–ï –ü–†–û–ì–†–ï–°–ê –ò CSV-–¢–û –î–ò–†–ï–ö–¢–ù–û –í –†–ï–ü–û–¢–û
      - name: Commit Loot (Auto-Save Data & Progress)
        uses: stefanzweifel/git-auto-commit-action@v5
        if: always() # <-- –¢–û–í–ê –ï –ö–õ–Æ–ß–™–¢! –ò–∑–ø—ä–ª–Ω—è–≤–∞ —Å–µ –≤–∏–Ω–∞–≥–∏, –¥–æ—Ä–∏ –ø—Ä–∏ –≥—Ä–µ—à–∫–∞ –≥–æ—Ä–µ.
        with:
          commit_message: "ü§ñ Loot Secure: Saved data & progress from Page ${{ steps.scraper.outcome }}"
          # –¢—É–∫ –∫–∞–∑–≤–∞–º–µ –Ω–∞ Git –¥–∞ –≥–ª–µ–¥–∞ –∏ TXT —Ñ–∞–π–ª–∞, –∏ CSV —Ñ–∞–π–ª–æ–≤–µ—Ç–µ
          file_pattern: "last_page.txt scraped_data/*.csv" 
          skip_dirty_check: false
