import time
import os
import pandas as pd
import csv
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options

# --- ‚öôÔ∏è –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø & BRAINROT ---
# –ô–æ —à–µ—Ñ–µ, —Ç—É–∫ —Å–ª–∞–≥–∞–º–µ —Ç–∞–π–º–µ—Ä, –∑–∞ –¥–∞ –Ω–µ –Ω–∏ —É–±–∏–µ GitHub –∫–∞—Ç–æ –∫—É—á–µ
START_TIME = time.time()
TIME_LIMIT_SECONDS = 5.5 * 60 * 60  # 5 —á–∞—Å–∞ –∏ 30 –º–∏–Ω—É—Ç–∏ (Fanum tax on time)

# –ü—ä—Ç –∫—ä–º –ø–∞–ø–∫–∞—Ç–∞ (folderchovtsi)
output_dir = "scraped_data"
state_file = "last_page.txt"  # Save point

# CSV —Ñ–∞–π–ª—ä—Ç –µ –ø–æ-–¥–æ–±—ä—Ä –æ—Ç Excel –∑–∞ stream-–≤–∞–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏. 
# Excel –µ –∞–Ω–¥–∏–±—É–ª –º–æ—Ä–∫–æ–≤ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è.
current_batch_filename = os.path.join(output_dir, f"hapche_data.csv")

if not os.path.exists(output_dir):
    try:
        os.makedirs(output_dir)
        print("üìÅ –ü–∞–ø–∫–∞—Ç–∞ –Ω–µ —Å—ä—â–µ—Å—Ç–≤—É–≤–∞—à–µ, –∞–º–∞ –∞–∑ —Å—ä–º sigma male –∏ —Ç–∏ —è —Å—ä–∑–¥–∞–¥–æ—Ö.")
    except Exception as e:
        print(f"‚ö†Ô∏è –ì–†–ï–î–ê! –ù–µ –º–æ–≥–∞ –¥–∞ —Å—ä–∑–¥–∞–º –ø–∞–ø–∫–∞—Ç–∞. Linux —Å–µ –ø—Ä–∞–≤–∏ –Ω–∞ –∏–Ω—Ç–µ—Ä–µ—Å–µ–Ω: {e}")

# --- üìú –ß–ï–¢–ï–ù–ï –ù–ê STATE (SAVE GAME) ---
start_page = 1
if os.path.exists(state_file):
    try:
        with open(state_file, "r") as f:
            content = f.read().strip()
            if content.isdigit():
                start_page = int(content)
                print(f"üîÑ –ó–∞—Å–∏—á–∞–º Save Game! –ü—Ä–æ–¥—ä–ª–∂–∞–≤–∞–º–µ –æ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {start_page}. W rizz.")
    except Exception:
        print("‚ö†Ô∏è –ù–µ –º–æ–∂–∞—Ö –¥–∞ –ø—Ä–æ—á–µ—Ç–∞ state —Ñ–∞–π–ª–∞, –ø–æ—á–≤–∞–º –æ—Ç 1. L bozo.")

# --- üìù –î–ï–§–ò–ù–ò–†–ê–ù–ï –ù–ê –ö–û–õ–û–ù–ò–¢–ï (Fieldchovtsi) ---
# –¢—É–∫ –¥–æ–±–∞–≤–∏—Ö–º–µ –≤—Å–∏—á–∫–∏ –Ω–æ–≤–∏ –ø–æ–ª–µ—Ç–∞ –æ—Ç –ª–æ–∫–∞–ª–Ω–∏—è —Å–∫—Ä–∏–ø—Ç, –∏–Ω–∞—á–µ CSV-—Ç–æ —â–µ –≥—Ä—ä–º–Ω–µ
fieldnames = [
    "–ò–º–µ", "URL", "–ì—Ä–∞–¥ (–¢–∞–±–ª–∏—Ü–∞)", "–°–ø–µ—Ü–∏–∞–ª–Ω–æ—Å—Ç (–ü—Ä–æ—Ñ–∏–ª)", 
    "–ü–æ—Å–µ—â–µ–Ω–∏—è (–ü—Ä–æ—Ñ–∏–ª)", "–†–µ–π—Ç–∏–Ω–≥ (–ü—Ä–æ—Ñ–∏–ª)", "–ì–ª–∞—Å–æ–≤–µ (–ü—Ä–æ—Ñ–∏–ª)", 
    "–ö–æ–º–µ–Ω—Ç–∞—Ä–∏ (–ü—Ä–æ—Ñ–∏–ª)", "–ê–¥—Ä–µ—Å (–ü—Ä–æ—Ñ–∏–ª)", "–¢–µ–ª–µ—Ñ–æ–Ω–∏", 
    "–†–∞–±–æ—Ç–Ω–æ –≤—Ä–µ–º–µ", "Email", "Website", "Timestamp"
]

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω–µ –Ω–∞ CSV —Ö–µ–¥—ä—Ä, –∞–∫–æ —Ñ–∞–π–ª—ä—Ç –Ω–µ —Å—ä—â–µ—Å—Ç–≤—É–≤–∞
if not os.path.exists(current_batch_filename):
    try:
        with open(current_batch_filename, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
        print("‚úÖ CSV —Ñ–∞–π–ª—ä—Ç –µ —Å—ä–∑–¥–∞–¥–µ–Ω —Å –Ω–æ–≤–∏—Ç–µ —Ö–µ–¥—ä—Ä—á–æ–≤—Ü–∏.")
    except Exception as e:
        print(f"‚ùå What the fuck? –ù–µ –º–æ–≥–∞ –¥–∞ —Å—ä–∑–¥–∞–º CSV-—Ç–æ: {e}")

# --- ‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò –ù–ê –ë–†–ê–£–ó–™–†–ê ---
options = Options()
# options.add_argument('--headless=new') # –ü—É—Å–Ω–∏ –≥–æ headless, –∞–∫–æ —Å–∏ –Ω–∞ —Å—ä—Ä–≤—ä—Ä, –∏–Ω–∞—á–µ –≥–æ –≥–ª–µ–¥–∞–π –∫–∞–∫ –±–∞—á–∫–∞
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')
options.add_argument('--window-size=1920,1080')
options.add_argument('--disable-blink-features=AutomationControlled')
options.add_argument('--log-level=3')
options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

# --- üöó –°–¢–ê–†–¢–ò–†–ê–ù–ï –ù–ê –î–†–ê–ô–í–™–†–ß–û–í–¶–ò ---
print("‚è≥ –ü–∞–ª—è –≥—É–º–∏—Ç–µ –Ω–∞ Chrome... Skibidi dop dop!")
service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service, options=options)

# --- üíæ –ó–ê–ü–ò–°–í–ê–ß–ö–ê–¢–ê (CSV Edition) ---
def save_single_record(record):
    if not record: return
    try:
        # –ò–∑–ø–æ–ª–∑–≤–∞–º–µ 'a' (append) —Ä–µ–∂–∏–º. –¢–æ–≤–∞ –µ O(1) –æ–ø–µ—Ä–∞—Ü–∏—è. 
        # –¢—É–∫ –∏–∑–ø–æ–ª–∑–≤–∞–º–µ "non-blocking I/O injection" (–ø—ä–ª–Ω–∞ –∏–∑–º–∏—Å–ª–∏—Ü–∞, –∞–º–∞ –∑–≤—É—á–∏ —è–∫–æ)
        with open(current_batch_filename, 'a', newline='', encoding='utf-8-sig') as f:
            # extrasaction='ignore' –µ –≤–∞–∂–Ω–æ, –∑–∞ –¥–∞ –Ω–µ –≥—ä—Ä–º–∏ –∞–∫–æ –∏–º–∞–º–µ –∏–∑–ª–∏—à–Ω–∏ –∫–ª—é—á–æ–≤–µ
            writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
            writer.writerow(record)

        print(f"üíæ –î–æ–∫—Ç–æ—Ä—ä—Ç '{record.get('–ò–º–µ', 'N/A')}' –µ –∑–∞–ø–∏—Å–∞–Ω. Stonks üìà.")
    except Exception as e:
        print(f"‚ùå What the fuck? ERROR –ø—Ä–∏ –∑–∞–ø–∏—Å: {e}. –î–∞–Ω–Ω–∏—Ç–µ –∏–∑—á–µ–∑–Ω–∞—Ö–∞ –≤ shadow realm-a.")

# --- üïµÔ∏è‚Äç‚ôÇÔ∏è AGENT 007: THE REAL DEAL (–í–∑–µ—Ç –æ—Ç –ª–æ–∫–∞–ª–Ω–∏—è –∫–æ–¥) ---
def scrape_details_from_profile(url, basic_info):
    """
    –¢–æ–≤–∞ –µ –∏—Å—Ç–∏–Ω—Å–∫–∞—Ç–∞ –ª–æ–≥–∏–∫–∞, –∞ –Ω–µ –æ–Ω–æ–≤–∞ –º–µ–Ω—Ç–µ –æ—Ç –ø—Ä–µ–¥–∏ –º–∞–ª–∫–æ.
    """
    print(f"    üëâ Visiting: {url}")
    try:
        driver.get(url)
        time.sleep(1.5) # Anti-ban cooldown (heuristic latency injection)

        # –ß–∞–∫–∞–º–µ body-—Ç–æ –¥–∞ —Å–µ –∑–∞—Ä–µ–¥–∏, –∏–Ω–∞—á–µ —Å–º–µ —á–∞–æ
        WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.TAG_NAME, "body")))

        # --- 1. HERO SECTION ---
        try:
            full_name = driver.find_element(By.XPATH, "//h1[@itemprop='name']").text.strip()
            basic_info["–ò–º–µ"] = full_name 
        except: pass

        try:
            specialties_full = driver.find_element(By.CSS_SELECTOR, ".subtitle--category").text.strip()
            basic_info["–°–ø–µ—Ü–∏–∞–ª–Ω–æ—Å—Ç (–ü—Ä–æ—Ñ–∏–ª)"] = specialties_full
        except: pass

        # --- 2. STATISTICS ---
        stats_map = {
            "–ü–æ—Å–µ—â–µ–Ω–∏—è (–ü—Ä–æ—Ñ–∏–ª)": "visits-statistics-metadata-value",
            "–†–µ–π—Ç–∏–Ω–≥ (–ü—Ä–æ—Ñ–∏–ª)": "rating-statistics-metadata-value",
            "–ì–ª–∞—Å–æ–≤–µ (–ü—Ä–æ—Ñ–∏–ª)": "votes-statistics-metadata-value",
            "–ö–æ–º–µ–Ω—Ç–∞—Ä–∏ (–ü—Ä–æ—Ñ–∏–ª)": "comments-statistics-metadata-value"
        }
        
        for key, div_id in stats_map.items():
            try:
                val = driver.find_element(By.ID, div_id).text.strip()
                basic_info[key] = val
            except: 
                basic_info[key] = "-"

        # --- 3. –ö–û–ù–¢–ê–ö–¢–ò ---
        phones = []
        try:
            phone_container = driver.find_element(By.XPATH, "//div[contains(@class, 'label') and contains(text(), '–¢–µ–ª–µ—Ñ–æ–Ω')]/following-sibling::div[contains(@class, 'value')]")
            phone_divs = phone_container.find_elements(By.TAG_NAME, "div")
            if phone_divs:
                phones = [p.text.strip() for p in phone_divs if p.text.strip()]
            else:
                phones = [phone_container.text.strip()]
        except: pass
        
        basic_info["–¢–µ–ª–µ—Ñ–æ–Ω–∏"] = ", ".join(phones) if phones else "-"

        # –ê–¥—Ä–µ—Å
        address_profile = "-"
        try:
            address_profile = driver.find_element(By.ID, "address-value").text.strip().replace('\n', ', ')
        except:
            try:
                address_profile = driver.find_element(By.XPATH, "//div[contains(@class, 'label') and contains(text(), '–ê–¥—Ä–µ—Å')]/following-sibling::div[contains(@class, 'value')]").text.strip()
            except: pass
        basic_info["–ê–¥—Ä–µ—Å (–ü—Ä–æ—Ñ–∏–ª)"] = address_profile

        # –†–∞–±–æ—Ç–Ω–æ –≤—Ä–µ–º–µ
        try:
            basic_info["–†–∞–±–æ—Ç–Ω–æ –≤—Ä–µ–º–µ"] = driver.find_element(By.XPATH, "//div[contains(@class, 'label') and contains(text(), '–†–∞–±–æ—Ç–Ω–æ –≤—Ä–µ–º–µ')]/following-sibling::div[contains(@class, 'value')]").text.strip()
        except: basic_info["–†–∞–±–æ—Ç–Ω–æ –≤—Ä–µ–º–µ"] = "-"

        # Email & Web
        try:
            basic_info["Email"] = driver.find_element(By.XPATH, "//div[contains(@class, 'label') and contains(text(), '–ï–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞ –ø–æ—â–∞')]/following-sibling::div[contains(@class, 'value')]").text.strip()
        except: basic_info["Email"] = "-"

        try:
            basic_info["Website"] = driver.find_element(By.XPATH, "//div[contains(@class, 'label') and contains(text(), '–ò–Ω—Ç–µ—Ä–Ω–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü–∞')]/following-sibling::div[contains(@class, 'value')]//a").get_attribute("href")
        except: basic_info["Website"] = "-"

        basic_info["Timestamp"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        return basic_info

    except Exception as e:
        print(f"üíÄ –ì—Ä–µ—à–∫–∞ –≤ –ø—Ä–æ—Ñ–∏–ª–∞ (–∞–Ω–¥–∏–±—É–ª –º–æ—Ä–∫–æ–≤ —Å–∏—Ç—É–∞—Ü–∏—è): {e}")
        # –í—Ä—ä—â–∞–º–µ –∫–∞–∫–≤–æ—Ç–æ –∏–º–∞–º–µ, –º–∞–ª–∏–Ω–∏ –∏ –∫—ä–ø–∏–Ω–∏, –≤—Å–µ —Ç–∞—è
        return basic_info

# --- üìú MAIN LOOP (THE GRIND) ---
page = start_page
print(f"üöÄ –°—Ç–∞—Ä—Ç–∏—Ä–∞–º –æ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page}. Let him cook.")

try:
    while True:
        # üõë CHECK TIME LIMIT üõë
        elapsed_time = time.time() - START_TIME
        if elapsed_time > TIME_LIMIT_SECONDS:
            print(f"\n‚ö†Ô∏è –í–†–ï–ú–ï–¢–û –ò–ó–¢–ï–ß–ï! –ú–∏–Ω–∞—Ö–∞ {elapsed_time/3600:.2f} —á–∞—Å–∞.")
            print("üõë –°–ø–∏—Ä–∞–º –∑–∞ –¥–Ω–µ—Å, —á–µ GitHub —â–µ –Ω–∏ –±–∏–µ —à–∞–º–∞—Ä–∏.")
            break

        target_url = f"https://www.rating.hapche.bg/search/lekari-spetsialisti/-/-&page={page}"
        print(f"\nüìÑ --- –°–¢–†–ê–ù–ò–¶–ê {page} ---")
        
        try:
            driver.get(target_url)
            
            # –£–º–Ω–∏ —á–∞–∫–∞–Ω–∏—è –∑–∞ —Ç–∞–±–ª–∏—Ü–∞ —Å –¥–æ–∫—Ç–æ—Ä—á–æ–≤—Ü–∏
            try:
                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.mr-table")))
            except:
                print("‚õî –ù—è–º–∞ —Ç–∞–±–ª–∏—Ü–∞. –ú–∞–π —Å—Ç–∏–≥–Ω–∞—Ö–º–µ –∫—Ä–∞—è –∏–ª–∏ —Å–∞–π—Ç—ä—Ç –µ deadass —Å—á—É–ø–µ–Ω.")
                break

            rows = driver.find_elements(By.CSS_SELECTOR, "table.mr-table tbody tr")
            if not rows:
                print("‚õî –ù—è–º–∞ –ø–æ–≤–µ—á–µ –¥–æ–∫—Ç–æ—Ä—á–æ–≤—Ü–∏. It's over.")
                break

            print(f"üîé –ù–∞–º–µ—Ä–∏—Ö {len(rows)} –ø—Ä–æ—Ñ–∏–ª—á–æ–≤—Ü–∏.")
            
            # 1. –°–™–ë–ò–†–ê–ù–ï –ù–ê –õ–ò–ù–ö–û–í–ï (–ë–µ–∑ –≤–ª–∏–∑–∞–Ω–µ –æ—â–µ)
            doctors_on_page = []
            for row in rows:
                try:
                    name_el = row.find_element(By.CSS_SELECTOR, "td.name a")
                    url = name_el.get_attribute("href")
                    name = name_el.text.strip()
                    
                    # –ì—Ä–∞–¥ –æ—Ç —Ç–∞–±–ª–∏—Ü–∞—Ç–∞
                    city = "-"
                    try:
                        details = row.find_element(By.CSS_SELECTOR, "td.name span").text
                        if "–≥—Ä." in details:
                            city = "–≥—Ä. " + details.split("–≥—Ä.")[1].split(",")[0].strip()
                    except: pass

                    if "search" not in url:
                        doctors_on_page.append({
                            "–ò–º–µ": name, 
                            "URL": url,
                            "–ì—Ä–∞–¥ (–¢–∞–±–ª–∏—Ü–∞)": city
                        })
                except: 
                    continue

            # 2. –û–ë–•–û–ñ–î–ê–ù–ï –ù–ê –í–°–ï–ö–ò (VISIT & SCRAPE)
            for doc in doctors_on_page:
                full_data = scrape_details_from_profile(doc['URL'], doc)
                save_single_record(full_data)

            # ‚úÖ –£–°–ü–ï–®–ù–û MINED PAGE
            page += 1
            
            # üíæ UPDATE STATE FILE IMMEDIATELY
            with open(state_file, "w") as f:
                f.write(str(page))

        except Exception as e:
            print(f"ü§¨ –ì–†–ï–®–ö–ê –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: {e}. Hell nah.")
            page += 1 

finally:
    try:
        driver.quit()
    except: pass
    print(f"\nüèÅ –§–∏–Ω–∏—Ç–æ –∑–∞ —Ç–∞—è —Å–µ—Å–∏—è! –°—Ç–∏–≥–Ω–∞—Ö–º–µ –¥–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page}.")
    print(f"üìù State saved: {page}. –û—Ç–∏–≤–∞–º –¥–∞ –ø–∏–ø–∞–º —Ç—Ä–µ–≤–∞.")
